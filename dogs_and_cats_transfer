{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Dogs and Cats (Transfer Learning)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeyoor/iusb-applied-deep-learning-lecture/blob/feature%2F2019-09-18-lecture/dogs_and_cats_transfer\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edfbxDDh2AEs"
      },
      "source": [
        "## Dogs and Cats (Transfer Learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JteE4XwwtUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python\n",
        "#Jeyan Oorjitham\n",
        "#Applied Deep Learning\n",
        "#CSCI-C690\n",
        "#Dr. James Wolfer\n",
        "\n",
        "#Assignment 2a: Dogs and Cats\n",
        "\n",
        "import os\n",
        "import time as t\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
        "\n",
        "def preprocess_input_vgg(x):\n",
        "    \"\"\"Wrapper around keras.applications.vgg16.preprocess_input()\n",
        "    to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n",
        "    `preprocessing_function` argument.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : a numpy 3darray (a single image to be preprocessed)\n",
        "    \n",
        "    Note we cannot pass keras.applications.vgg16.preprocess_input()\n",
        "    directly to to keras.preprocessing.image.ImageDataGenerator's\n",
        "    `preprocessing_function` argument because the former expects a\n",
        "    4D tensor whereas the latter expects a 3D tensor. Hence the\n",
        "    existence of this wrapper.\n",
        "    \n",
        "    Returns a numpy 3darray (the preprocessed image).\n",
        "    \n",
        "    \"\"\"\n",
        "    from keras.applications.vgg16 import preprocess_input\n",
        "    X = np.expand_dims(x, axis=0)\n",
        "    X = preprocess_input(X)\n",
        "    return X[0]\n",
        "\n",
        "def save_prediction_examples(num_examples=1, validation_image_generator=None, model=None, folder_path='results/', model_name='name'):\n",
        "    \"\"\"Helper method to save examples of images and prediction probabilities\"\"\"\n",
        "    X_val_sample, _ = next(validation_image_generator)\n",
        "    y_pred = model.predict(X_val_sample)\n",
        "    for idx, x, y in zip(range(num_examples), X_val_sample[:num_examples], y_pred.flatten()[:num_examples]):\n",
        "        s = pd.Series({'Cat': 1-y, 'Dog': y})\n",
        "        axes = s.plot(kind='bar')\n",
        "        axes.set_xlabel('Class')\n",
        "        axes.set_ylabel('Probability')\n",
        "        axes.set_ylim([0, 1])\n",
        "        plt.savefig(timestamp + \"/\" + model_name + \"_result_graph_\" + str(idx) + \".png\")\n",
        "        plt.imsave(timestamp + \"/\" + model_name + \"_prediction_sample_\" + str(idx) + \".png\", x)\n",
        "\n",
        "#create constants\n",
        "SAMPLES_PER_EPOCH = 16\n",
        "#using 10 epochs for training test\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 1\n",
        "VALIDATION_STEPS = 32\n",
        "#dump full model to disk every 10 epochs\n",
        "MODEL_SAVER_PERIOD = EPOCHS / 10\n",
        "\n",
        "#create training and validation data generators\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(directory='dogs_cats_data/train',\n",
        "                                                    target_size=[224, 224],\n",
        "                                                    batch_size=16,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
        "validation_generator = validation_datagen.flow_from_directory(directory='dogs_cats_data/validation',\n",
        "                                                              target_size=[224, 224],\n",
        "                                                              batch_size=16,\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "#initialize existing application nets\n",
        "xception = Xception(weights='imagenet')\n",
        "vgg16 = VGG16(weights='imagenet')\n",
        "resnet50 = ResNet50(weights='imagenet')\n",
        "\n",
        "#bind 1D sigmoid output prediction to second-to-last layer\n",
        "final_vgg16_layer = vgg16.get_layer('fc2').output\n",
        "vgg16_prediction = Dense(output_dim=1, activation='sigmoid', name='logit')(final_vgg16_layer)\n",
        "vgg16_model = Model(input=vgg16.input, output=vgg16_prediction)\n",
        "\n",
        "final_xception_layer = xception.get_layer('avg_pool').output\n",
        "xception_prediction = Dense(output_dim=1, activation='sigmoid', name='logit')(final_xception_layer)\n",
        "xception_model = Model(input=xception.input, output=xception_prediction)\n",
        "\n",
        "final_resnet50_layer = resnet50.get_layer('flatten_1').output\n",
        "resnet50_prediction = Dense(output_dim=1, activation='sigmoid', name='logit')(final_resnet50_layer)\n",
        "resnet50_model = Model(input=resnet50.input, output=resnet50_prediction)\n",
        "\n",
        "timestamp = \"results/\" + t.strftime(\"%Y%m%d-%H%M%S\")\n",
        "if not os.path.exists(timestamp):\n",
        "    os.makedirs(timestamp)\n",
        "\n",
        "vgg16_csv_logger = CSVLogger(timestamp + '/vgg16_training_log.csv', append=True, separator=',')\n",
        "vgg16_model_saver = ModelCheckpoint(timestamp + '/vgg16.weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=MODEL_SAVER_PERIOD)\n",
        "xception_csv_logger = CSVLogger(timestamp + '/xception_training_log.csv', append=True, separator=',')\n",
        "xception_model_saver = ModelCheckpoint(timestamp + '/xception.weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=MODEL_SAVER_PERIOD)\n",
        "resnet50_csv_logger = CSVLogger(timestamp + '/resnet50_training_log.csv', append=True, separator=',')\n",
        "resnet50_model_saver = ModelCheckpoint(timestamp + '/resnet50.weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=MODEL_SAVER_PERIOD)\n",
        "\n",
        "#freeze vgg16 feature layers\n",
        "for layer in vgg16_model.layers:\n",
        "    if layer.name in ['fc1', 'fc2', 'logit']:\n",
        "        continue\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in xception_model.layers:\n",
        "    if layer.name in ['avg_pool', 'logit']:\n",
        "        continue\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in resnet50_model.layers:\n",
        "    if layer.name in ['avg_pool', 'flatten_1', 'logit']:\n",
        "        continue\n",
        "    layer.trainable = False\n",
        "\n",
        "sgd = SGD(lr=1e-4, momentum=0.9)\n",
        "\n",
        "#compile and train models\n",
        "vgg16_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "vgg16_model.fit_generator(train_generator,\n",
        "                    samples_per_epoch=SAMPLES_PER_EPOCH,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    callbacks=[vgg16_csv_logger, vgg16_model_saver]);\n",
        "\n",
        "xception_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "xception_model.fit_generator(train_generator,\n",
        "                    samples_per_epoch=SAMPLES_PER_EPOCH,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    callbacks=[xception_csv_logger, xception_model_saver]);\n",
        "\n",
        "resnet50_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.fit_generator(train_generator,\n",
        "                    samples_per_epoch=SAMPLES_PER_EPOCH,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    callbacks=[resnet50_csv_logger, resnet50_model_saver]);\n",
        "\n",
        "#save 4 example predictions with images for each model\n",
        "save_prediction_examples(num_examples=4, validation_image_generator=validation_generator, model=vgg16_model, folder_path=timestamp, model_name='vgg16')\n",
        "save_prediction_examples(num_examples=4, validation_image_generator=validation_generator, model=xception_model, folder_path=timestamp, model_name='xception')\n",
        "save_prediction_examples(num_examples=4, validation_image_generator=validation_generator, model=resnet50_model, folder_path=timestamp, model_name='resnet50')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}